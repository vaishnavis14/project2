---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Vaishnavi Sathiyamoorthy vs25229

### Introduction 

Cardiovascular diseases cause the most number of deaths around the world. In fact, it is responsible for approximately 31% of deaths. This dataset includes 11 factors that could help predict the the possibility of an individual having cardiovascular disease. These factors are age, sex, type of chest pain, resting blood pressure, cholesterol, fasting blood sugar, resting electrocardiogram results, maximum heartrate, whether exercise induces angina, the old peak, and the type of slope of the peak during exercise. This dataset contains 918 observations and was found on Kaggle. 410 of the observations have heart disease and 508 of the observations do not have heart disease. The goal of this project is to predict whether an individual has heart disease based on these factors. 

```{R}
library(tidyverse)
heart_data <- read_csv("heart.csv")
head(heart_data) 
```

### Cluster Analysis

```{R}
library(cluster)
sil_width<-vector()
for(i in 2:10){  
  pam_fit <- pam(heart_data, k = i)  
  sil_width[i] <- pam_fit$silinfo$avg.width  
}
ggplot()+geom_line(aes(x=1:10,y=sil_width))+scale_x_continuous(name="k",breaks=1:10)
heart_pam <- heart_data %>% pam(k = 2)
heart_pam$silinfo$avg.width

library(GGally)
heart_data %>% mutate(cluster=as.factor(heart_pam$clustering)) %>% ggpairs(cols = 1:12, aes(color = cluster))
#How do you make this graph more readable?
```

The graph shows that the highest silhouette width is present when k = 2. The pam function shows that the average silhouette is 0.7 for 2 clusters. This means that a reasonable structure has been found.
    
    
### Dimensionality Reduction with PCA

```{R}
heart_numeric_data <- heart_data %>% select(Age, RestingBP, Cholesterol, MaxHR, Oldpeak)
pca1 <- princomp(heart_numeric_data, cor = T)
summary(pca1, loadings = T)
```

Discussions of PCA here. 

###  Linear Classifier

```{R}
logistic_fit <- glm((HeartDisease == 1) ~ Age + RestingBP + Cholesterol + MaxHR + Oldpeak, data = heart_data, family="binomial")

prob_reg <- predict(logistic_fit, new_data = heart_data, type = "response")
class_diag(prob_reg, heart_data$HeartDisease, positive = 1)
```

```{R}
k <- 11
data <- sample_frac(heart_data) #randomly order rows
folds <- rep(1:k, length.out = nrow(data)) #create folds

diags <- NULL

i = 1
for(i in 1:k){
# create training and test sets
train <- data[folds!= i,] 
test <- data[folds == i,] 
truth <- test$HeartDisease

# train model
fit <- glm(HeartDisease ~ Age + RestingBP + Cholesterol + MaxHR + Oldpeak, data = test, family = "binomial")

# test model
probs <- predict(fit, test, type = "response")

# get performance metrics for each fold
diags <- rbind(diags, class_diag(probs, truth, positive = 1)) }
#average performance metrics across all folds
summarize_all(diags, mean)
```

Discussion here

### Non-Parametric Classifier

```{R}
library(caret)
knn_fit <- knn3(HeartDisease ~  Age + RestingBP + Cholesterol + MaxHR + Oldpeak, data = heart_data)
prob_knn <- predict(knn_fit, heart_data)[,2]
class_diag(prob_knn, heart_data$HeartDisease, positive = 1)
```

```{R}
k = 11

data <- sample_frac(heart_data) #randomly order rows
folds <- rep(1:k, length.out = nrow(data)) #create folds

diags <- NULL

i = 1
for(i in 1:k){
# create training and test sets
train <- data[folds != i,] 
test <- data[folds == i,] 
truth <- test$HeartDisease

# train model
fit <- knn3(HeartDisease ~ Age + RestingBP + Cholesterol + MaxHR + Oldpeak, data=test)

# test model
probs <- predict(fit, test)[,2]

# get performance metrics for each fold
diags <- rbind(diags, class_diag(probs, truth, positive = 1)) }

#average performance metrics across all folds
summarize_all(diags, mean)
```

Discussion


### Regression/Numeric Prediction

```{R}
# regression model code here
```

```{R}
# cross-validation of regression model here
```

Discussion

### Python 

```{R}
library(reticulate)
```

```{python}
# python code here
```

Discussion

### Concluding Remarks

Include concluding remarks here, if any




